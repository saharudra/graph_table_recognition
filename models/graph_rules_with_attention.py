import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv

class GraphRulesWithAttentionMultiClass(nn.Module):
    """
    GraphRulesMultiLabel processes graphs generated by rules that have
    both same-row and same-col label associated with each of the edges
    in a multi-label fashion with a single head performing both the row
    and column classifications.
    Row and Column adjacency matrices are combined at each node level 
    to create the meta graph after finding individual adjacency matrix
    using corresponding rules.
    """
    def __init__(self, base_params):
        super(GraphRulesWithAttentionMultiClass, self).__init__()
        self.base_params = base_params
        self.base_params.num_classes = 3

        # position transformation layer
        self.conv1 = GATConv(self.base_params.num_node_features, self.base_params.num_hidden_features * 2)
        self.conv2 = GATConv(self.base_params.num_hidden_features * 2, self.base_params.num_hidden_features * 2)
        self.conv3 = GATConv(self.base_params.num_hidden_features * 2, self.base_params.num_hidden_features)

        # edge feature generation layers
        self.lin_pos = nn.Sequential(
            nn.Linear(self.base_params.num_hidden_features * 2, self.base_params.num_hidden_features * 2),
            nn.ReLU(inplace=True),
            nn.Linear(self.base_params.num_hidden_features * 2, self.base_params.num_hidden_features * 2)
        )

        # classification head
        # Using BCEWithLogitsLoss
        self.lin = nn.Sequential(
            nn.Linear(self.base_params.num_hidden_features * 2, self.base_params.num_hidden_features),
            nn.ReLU(inplace=True),
            nn.Linear(self.base_params.num_hidden_features, self.base_params.num_hidden_features),
            nn.ReLU(inplace=True),
            nn.Linear(self.base_params.num_hidden_features, self.base_params.num_classes)
        )
    
    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        # Transform position features
        position_features = F.relu(self.conv1(x, edge_index))
        position_features = F.relu(self.conv2(position_features, edge_index))
        position_features = F.relu(self.conv3(position_features, edge_index))

        # Edge feature generation
        n1_position_features = position_features[edge_index[0]]
        n2_position_features = position_features[edge_index[1]]
        edge_pos_features = torch.cat((n1_position_features, n2_position_features), dim=1)

        # Transform edge features
        edge_pos_features = F.relu(self.lin_pos(edge_pos_features))

        # Get edge predictions
        edge_pred = self.lin(edge_pos_features)  # Using nn.CrossEntropyLoss(), no softmax

        return edge_pred
    